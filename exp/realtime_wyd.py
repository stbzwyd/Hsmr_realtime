from lib.kits.hsmr_demo import *
import cv2
import torch
import open3d as o3d
import numpy as np

def main():
    # â›©ï¸ 0. Preparation.
    args = parse_args()
    monitor = TimeMonitor()

    # â›©ï¸ 1. Initialize Detector and Pipeline.
    with monitor('Detector Initialization'):
        get_logger(brief=True).info('ğŸ§± Building detector.')
        detector = build_detector(
            batch_size=args.det_bs,
            max_img_size=args.det_mis,
            device=args.device,
        )

    with monitor('Pipeline Initialization'):
        get_logger(brief=True).info('ğŸ§± Building recovery pipeline.')
        pipeline = build_inference_pipeline(model_root=args.model_root, device=args.device)

    # â›©ï¸ 2. Setup Camera and Visualization.
    cap = cv2.VideoCapture(0)  # æ‰“å¼€æ‘„åƒå¤´
    if not cap.isOpened():
        get_logger(brief=True).error('ğŸš« Failed to open camera!')
        return

    vis = o3d.visualization.Visualizer()
    vis.create_window(window_name='HSMR Real-Time Demo')

    # â›©ï¸ 3. Real-Time Loop.**************************
    get_logger(brief=True).info('ğŸ¥ Starting real-time demo...')
    while True:
        # è¯»å–æ‘„åƒå¤´å¸§
        ret, frame = cap.read()
        if not ret:
            get_logger(brief=True).error('ğŸš« Failed to read frame from camera!')
            break

        # é¢„å¤„ç†ï¼šæ£€æµ‹äººä½“å®ä¾‹
        with monitor('Detecting'):
            raw_imgs = [frame]  # å•å¸§è¾“å…¥
            detector_outputs = detector(raw_imgs)
            patches, det_meta = imgs_det2patches(raw_imgs, *detector_outputs, args.max_instances)
            if len(patches) == 0:
                get_logger(brief=True).warning('ğŸš« No human instance detected in this frame.')
                continue
            get_logger(brief=True).info(f'ğŸ” Detected {len(patches)} human instances.')

        # æ¨ç†ï¼šé€å¸§æ¢å¤éª¨éª¼å’Œç½‘æ ¼
        with monitor('Recovery'):
            patches_i = np.concatenate(patches, axis=0)  # (N, 256, 256, 3)
            patches_normalized_i = (patches_i - IMG_MEAN_255) / IMG_STD_255  # (N, 256, 256, 3)
            patches_normalized_i = patches_normalized_i.transpose(0, 3, 1, 2)  # (N, 3, 256, 256)
            with torch.no_grad():
                outputs = pipeline(patches_normalized_i)
            pd_params = {k: v.detach().cpu().clone() for k, v in outputs['pd_params'].items()}
            pd_cam_t = outputs['pd_cam_t'].detach().cpu().clone()

            # å‡†å¤‡ç½‘æ ¼
            m_skin, m_skel = prepare_mesh(pipeline, [pd_params])  # å•å¸§è¾“å…¥ï¼Œåˆ—è¡¨é•¿åº¦ä¸º1

        # å¯è§†åŒ–ï¼šå®æ—¶æ¸²æŸ“
        with monitor('Visualization'):
            if args.ignore_skel:
                m_skel = None
            results, full_cam_t = visualize_full_img(
                pd_cam_t, raw_imgs, det_meta, m_skin, m_skel, args.have_caption
            )

            # ä½¿ç”¨Open3Dæ¸²æŸ“ï¼ˆå‡è®¾m_skinå’Œm_skelæ˜¯Open3Då‡ ä½•å¯¹è±¡ï¼‰
            vis.clear_geometries()
            if m_skin:
                vis.add_geometry(m_skin[0])  # å•å¸§ç»“æœ
            if m_skel:
                vis.add_geometry(m_skel[0])
            vis.poll_events()
            vis.update_renderer()

        # æ˜¾ç¤ºåŸå§‹å›¾åƒï¼ˆå¯é€‰ï¼‰
        cv2.imshow('Camera Input', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # â›©ï¸ 4. Cleanup.
    cap.release()
    vis.destroy_window()
    cv2.destroyAllWindows()
    get_logger(brief=True).info('ğŸŠ Real-time demo finished!')
    monitor.report()

if __name__ == '__main__':
    main()